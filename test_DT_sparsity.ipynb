{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 50000\n",
    "trainset = torchvision.datasets.MNIST(root='~/Private/data', train=True,\n",
    "                                        download=False, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='~/Private/data', train=False,\n",
    "                                    download=False, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BS,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = ensemble.RandomForestClassifier(max_depth=5)\n",
    "# # clf = tree.DecisionTreeClassifier()\n",
    "# for images, labels in trainloader:\n",
    "#     clf.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "# dump(clf, 'trained_RandomForest.joblib') \n",
    "clf = load('trained_RandomForest.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576\n"
     ]
    }
   ],
   "source": [
    "for images, labels in testloader:\n",
    "    print(clf.score(images.view(images.size(0),-1).numpy(), labels.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4114805646411945\n"
     ]
    }
   ],
   "source": [
    "ttt = clf.estimators_\n",
    "sparsity = []\n",
    "for tt in ttt:\n",
    "    sp, table = utils.find_sparsity(tt)\n",
    "    sparsity.append(sp)\n",
    "print(np.mean(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = ttt[0]\n",
    "tt.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8438\n"
     ]
    }
   ],
   "source": [
    "class HanpiDecisionTree():\n",
    "    def __init__(self, DT):\n",
    "        self.DT = DT\n",
    "        self.depth = self.DT.get_depth()\n",
    "        self.features = utils.find_features(self.DT)\n",
    "        self.selected_features = []\n",
    "    \n",
    "    def select_features(self):\n",
    "        if self.depth > len(self.features):\n",
    "            self.selected_features = self.features\n",
    "        else:\n",
    "            self.selected_features = np.random.choice(self.features, self.depth, replace=False)\n",
    "    \n",
    "    def generate_input(self, X):\n",
    "        T = []\n",
    "        for i in self.selected_features:\n",
    "            line = X[:,i]\n",
    "            T.append(line)\n",
    "        T = np.array(T)\n",
    "        T = T.transpose()\n",
    "        return T\n",
    "\n",
    "    def predict(self, X):\n",
    "        if len(self.selected_features) == 0:\n",
    "            return self.DT.predict(X)\n",
    "        else:\n",
    "            XX = self.generate_input(X)\n",
    "            return self.DT.predict(XX)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        XX = self.generate_input(X)\n",
    "        self.DT.fit(XX, Y)\n",
    "\n",
    "class MoRandomForest():\n",
    "    def __init__(self, estimators):\n",
    "        self.estimators_ = []\n",
    "        self.transform(estimators)\n",
    "        \n",
    "    \n",
    "    def transform(self, estimators):\n",
    "        for i in range(len(estimators)):\n",
    "            self.estimators_.append(HanpiDecisionTree(estimators[i]))\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        predicted = []\n",
    "        for est in self.estimators_:\n",
    "            pred = est.predict(X)\n",
    "            results.append(pred)\n",
    "        results = np.array(results)\n",
    "        for i in range(len(results[0])):\n",
    "            this = results[:,i]\n",
    "            res = np.bincount(this.astype(np.int)).argmax()\n",
    "            predicted.append(res)\n",
    "        predicted = np.array(predicted)\n",
    "        return predicted\n",
    "\n",
    "clf = load('trained_RandomForest.joblib') \n",
    "m = MoRandomForest(clf.estimators_)\n",
    "for images, labels in testloader:\n",
    "    pred = m.predict(images.view(images.size(0),-1).numpy())\n",
    "    print((pred == labels.numpy()).sum() / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca429d7533b4df48be1234d489605d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dt in tqdm(m.estimators_):\n",
    "    # dt = m.estimators_[0]\n",
    "    # for images, labels in testloader:\n",
    "    #     pred = dt.predict(images.view(images.size(0),-1).numpy())\n",
    "    #     acc = (pred == labels.numpy()).sum() / len(labels)\n",
    "    #     sparsity, table = utils.find_sparsity(dt.DT)\n",
    "    #     print(f\"acc: {acc:.4f}, spasity: {sparsity:.4f}\")\n",
    "    dt.select_features()\n",
    "    for images, labels in trainloader:\n",
    "        dt.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "    # for images, labels in testloader:\n",
    "    #     pred = dt.predict(images.view(images.size(0),-1).numpy())\n",
    "    #     acc = (pred == labels.numpy()).sum() / len(labels)\n",
    "    #     sparsity, table = utils.find_sparsity(dt.DT)\n",
    "    #     print(f\"acc: {acc:.4f}, spasity: {sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8443\n"
     ]
    }
   ],
   "source": [
    "for images, labels in testloader:\n",
    "    pred = m.predict(images.view(images.size(0),-1).numpy())\n",
    "    print((pred == labels.numpy()).sum() / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e340a0a01ab186b377b016c01aa7d5d1230eddf285ffed81230a024c78a4da64"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
