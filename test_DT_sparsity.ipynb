{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 50000\n",
    "trainset = torchvision.datasets.MNIST(root='~/Private/data', train=True,\n",
    "                                        download=False, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='~/Private/data', train=False,\n",
    "                                    download=False, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BS,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = ensemble.RandomForestClassifier(max_depth=5)\n",
    "# # clf = tree.DecisionTreeClassifier()\n",
    "# for images, labels in trainloader:\n",
    "#     clf.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "# dump(clf, 'trained_RandomForest.joblib') \n",
    "clf = load('trained_RandomForest.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576\n"
     ]
    }
   ],
   "source": [
    "for images, labels in testloader:\n",
    "    print(clf.score(images.view(images.size(0),-1).numpy(), labels.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4114805646411945\n"
     ]
    }
   ],
   "source": [
    "ttt = clf.estimators_\n",
    "sparsity = []\n",
    "for tt in ttt:\n",
    "    sp, table = utils.find_sparsity(tt)\n",
    "    sparsity.append(sp)\n",
    "print(np.mean(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = ttt[0]\n",
    "tt.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/c38fmx112xqbpjb3y22pnq080000gn/T/ipykernel_20580/4232946341.py:53: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  res = np.bincount(this.astype(np.int)).argmax()\n"
     ]
    }
   ],
   "source": [
    "class HanpiDecisionTree():\n",
    "    def __init__(self, DT):\n",
    "        self.DT = DT\n",
    "        self.depth = self.DT.get_depth()\n",
    "        self.features = utils.find_features(self.DT)\n",
    "        self.selected_features = []\n",
    "    \n",
    "    def select_features(self):\n",
    "        if self.depth > len(self.features):\n",
    "            self.selected_features = self.features\n",
    "        else:\n",
    "            self.selected_features = np.random.choice(self.features, self.depth, replace=False)\n",
    "    \n",
    "    def generate_input(self, X):\n",
    "        T = []\n",
    "        for i in self.selected_features:\n",
    "            line = X[:,i]\n",
    "            T.append(line)\n",
    "        T = np.array(T)\n",
    "        T = T.transpose()\n",
    "        return T\n",
    "\n",
    "    def predict(self, X):\n",
    "        if len(self.selected_features) == 0:\n",
    "            return self.DT.predict(X)\n",
    "        else:\n",
    "            XX = self.generate_input(X)\n",
    "            return self.DT.predict(XX)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        XX = self.generate_input(X)\n",
    "        self.DT.fit(XX, Y)\n",
    "\n",
    "class MoRandomForest():\n",
    "    def __init__(self, estimators):\n",
    "        self.estimators_ = []\n",
    "        self.transform(estimators)\n",
    "        \n",
    "    \n",
    "    def transform(self, estimators):\n",
    "        for i in range(len(estimators)):\n",
    "            self.estimators_.append(HanpiDecisionTree(estimators[i]))\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        predicted = []\n",
    "        for est in self.estimators_:\n",
    "            pred = est.predict(X)\n",
    "            results.append(pred)\n",
    "        results = np.array(results)\n",
    "        for i in range(len(results[0])):\n",
    "            this = results[:,i]\n",
    "            res = np.bincount(this.astype(np.int32)).argmax()\n",
    "            predicted.append(res)\n",
    "        predicted = np.array(predicted)\n",
    "        return predicted\n",
    "\n",
    "clf = load('trained_RandomForest.joblib') \n",
    "m = MoRandomForest(clf.estimators_)\n",
    "for images, labels in testloader:\n",
    "    pred = m.predict(images.view(images.size(0),-1).numpy())\n",
    "    print((pred == labels.numpy()).sum() / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ab666e36844c9280be7f052606f153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dt in tqdm(m.estimators_):\n",
    "    # dt = m.estimators_[0]\n",
    "    # for images, labels in testloader:\n",
    "    #     pred = dt.predict(images.view(images.size(0),-1).numpy())\n",
    "    #     acc = (pred == labels.numpy()).sum() / len(labels)\n",
    "    #     sparsity, table = utils.find_sparsity(dt.DT)\n",
    "    #     print(f\"acc: {acc:.4f}, spasity: {sparsity:.4f}\")\n",
    "    dt.select_features()\n",
    "    for images, labels in trainloader:\n",
    "        dt.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "    # for images, labels in testloader:\n",
    "    #     pred = dt.predict(images.view(images.size(0),-1).numpy())\n",
    "    #     acc = (pred == labels.numpy()).sum() / len(labels)\n",
    "    #     sparsity, table = utils.find_sparsity(dt.DT)\n",
    "    #     print(f\"acc: {acc:.4f}, spasity: {sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/c38fmx112xqbpjb3y22pnq080000gn/T/ipykernel_20580/4232946341.py:53: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  res = np.bincount(this.astype(np.int)).argmax()\n"
     ]
    }
   ],
   "source": [
    "for images, labels in testloader:\n",
    "    pred = m.predict(images.view(images.size(0),-1).numpy())\n",
    "    print((pred == labels.numpy()).sum() / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022881451612903225\n"
     ]
    }
   ],
   "source": [
    "ttt = m.estimators_\n",
    "sparsity = []\n",
    "for tt in ttt:\n",
    "    sp, table = utils.find_sparsity(tt.DT)\n",
    "    sparsity.append(sp)\n",
    "print(np.mean(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e340a0a01ab186b377b016c01aa7d5d1230eddf285ffed81230a024c78a4da64"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
