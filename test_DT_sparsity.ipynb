{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from matplotlib import pyplot as plt\n",
    "import utils\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 50000\n",
    "trainset = torchvision.datasets.MNIST(root='~/Private/data', train=True,\n",
    "                                        download=False, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BS,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='~/Private/data', train=False,\n",
    "                                    download=False, transform=transforms.ToTensor())\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BS,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf.ccp_alpha = 0.01\n",
    "for images, labels in trainloader:\n",
    "    clf.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "for images, labels in testloader:\n",
    "    print(clf.score(images.view(images.size(0),-1).numpy(), labels.numpy()))\n",
    "utils.find_size(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "# clf.ccp_alpha = 0.01\n",
    "for images, labels in trainloader:\n",
    "    clf.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "for images, labels in testloader:\n",
    "    print(clf.score(images.view(images.size(0),-1).numpy(), labels.numpy()))\n",
    "utils.find_size(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = ensemble.RandomForestClassifier(max_depth=5)\n",
    "# # clf = tree.DecisionTreeClassifier()\n",
    "# for images, labels in trainloader:\n",
    "#     clf.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "# dump(clf, 'trained_RandomForest.joblib') \n",
    "clf = load('trained_RandomForest.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8576\n"
     ]
    }
   ],
   "source": [
    "for images, labels in testloader:\n",
    "    print(clf.score(images.view(images.size(0),-1).numpy(), labels.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4114805646411945\n"
     ]
    }
   ],
   "source": [
    "ttt = clf.estimators_\n",
    "sparsity = []\n",
    "for tt in ttt:\n",
    "    sp, table = utils.find_sparsity(tt)\n",
    "    sparsity.append(sp)\n",
    "print(np.mean(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = ttt[0]\n",
    "tt.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8438\n"
     ]
    }
   ],
   "source": [
    "class HanpiDecisionTree():\n",
    "    def __init__(self, DT):\n",
    "        self.DT = DT\n",
    "        self.depth = self.DT.get_depth()\n",
    "        self.features = utils.find_features(self.DT)\n",
    "        self.selected_features = []\n",
    "    \n",
    "    def select_features(self):\n",
    "        if self.depth > len(self.features):\n",
    "            self.selected_features = self.features\n",
    "        else:\n",
    "            self.selected_features = np.random.choice(self.features, self.depth, replace=False)\n",
    "    \n",
    "    def generate_input(self, X):\n",
    "        T = []\n",
    "        for i in self.selected_features:\n",
    "            line = X[:,i]\n",
    "            T.append(line)\n",
    "        T = np.array(T)\n",
    "        T = T.transpose()\n",
    "        return T\n",
    "\n",
    "    def predict(self, X):\n",
    "        if len(self.selected_features) == 0:\n",
    "            return self.DT.predict(X)\n",
    "        else:\n",
    "            XX = self.generate_input(X)\n",
    "            return self.DT.predict(XX)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        XX = self.generate_input(X)\n",
    "        self.DT.fit(XX, Y)\n",
    "\n",
    "class MoRandomForest():\n",
    "    def __init__(self, estimators):\n",
    "        self.estimators_ = []\n",
    "        self.transform(estimators)\n",
    "        \n",
    "    \n",
    "    def transform(self, estimators):\n",
    "        for i in range(len(estimators)):\n",
    "            self.estimators_.append(HanpiDecisionTree(estimators[i]))\n",
    "\n",
    "    def predict(self, X):\n",
    "        results = []\n",
    "        predicted = []\n",
    "        for est in self.estimators_:\n",
    "            pred = est.predict(X)\n",
    "            results.append(pred)\n",
    "        results = np.array(results)\n",
    "        for i in range(len(results[0])):\n",
    "            this = results[:,i]\n",
    "            res = np.bincount(this.astype(np.int32)).argmax()\n",
    "            predicted.append(res)\n",
    "        predicted = np.array(predicted)\n",
    "        return predicted\n",
    "\n",
    "clf = load('trained_RandomForest.joblib') \n",
    "m = MoRandomForest(clf.estimators_)\n",
    "for images, labels in testloader:\n",
    "    pred = m.predict(images.view(images.size(0),-1).numpy())\n",
    "    print((pred == labels.numpy()).sum() / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ab666e36844c9280be7f052606f153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dt in tqdm(m.estimators_):\n",
    "    # dt = m.estimators_[0]\n",
    "    # for images, labels in testloader:\n",
    "    #     pred = dt.predict(images.view(images.size(0),-1).numpy())\n",
    "    #     acc = (pred == labels.numpy()).sum() / len(labels)\n",
    "    #     sparsity, table = utils.find_sparsity(dt.DT)\n",
    "    #     print(f\"acc: {acc:.4f}, spasity: {sparsity:.4f}\")\n",
    "    dt.select_features()\n",
    "    for images, labels in trainloader:\n",
    "        dt.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "    # for images, labels in testloader:\n",
    "    #     pred = dt.predict(images.view(images.size(0),-1).numpy())\n",
    "    #     acc = (pred == labels.numpy()).sum() / len(labels)\n",
    "    #     sparsity, table = utils.find_sparsity(dt.DT)\n",
    "    #     print(f\"acc: {acc:.4f}, spasity: {sparsity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/c38fmx112xqbpjb3y22pnq080000gn/T/ipykernel_20580/4232946341.py:53: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  res = np.bincount(this.astype(np.int)).argmax()\n"
     ]
    }
   ],
   "source": [
    "for images, labels in testloader:\n",
    "    pred = m.predict(images.view(images.size(0),-1).numpy())\n",
    "    print((pred == labels.numpy()).sum() / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022881451612903225\n"
     ]
    }
   ],
   "source": [
    "ttt = m.estimators_\n",
    "sparsity = []\n",
    "for tt in ttt:\n",
    "    sp, table = utils.find_sparsity(tt.DT)\n",
    "    sparsity.append(sp)\n",
    "print(np.mean(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b76ca13cc2459798af4a53f25aba32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7932\n"
     ]
    }
   ],
   "source": [
    "for dt in tqdm(m.estimators_):\n",
    "    dt.DT.ccp_alpha = 0.01\n",
    "    for images, labels in trainloader:\n",
    "        dt.DT.fit(images.view(images.size(0),-1).numpy(), labels.numpy())\n",
    "    # for images, labels in testloader:\n",
    "    #     pred = dt.predict(images.view(images.size(0),-1).numpy())\n",
    "    #     acc = (pred == labels.numpy()).sum() / len(labels)\n",
    "    #     sparsity, table = utils.find_sparsity(dt.DT)\n",
    "    #     print(f\"acc: {acc:.4f}, spasity: {sparsity:.4f}\")\n",
    "for images, labels in testloader:\n",
    "    pred = m.predict(images.view(images.size(0),-1).numpy())\n",
    "    print((pred == labels.numpy()).sum() / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624495608264468e813ec6f6b2f88bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.87\n",
      "0.42896058435029033\n"
     ]
    }
   ],
   "source": [
    "sizes = []\n",
    "sps = []\n",
    "for dt in tqdm(m.estimators_):\n",
    "    size = utils.find_size(dt.DT)\n",
    "    sp, tb = utils.find_sparsity(dt.DT)\n",
    "    sps.append(sp)\n",
    "    sizes.append(size)\n",
    "print(np.mean(sizes))\n",
    "print(np.mean(sps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_405 <= 0.00\n",
      "|   |--- feature_155 <= 0.00\n",
      "|   |   |--- feature_372 <= 0.00\n",
      "|   |   |   |--- feature_486 <= 0.00\n",
      "|   |   |   |   |--- class: 7\n",
      "|   |   |   |--- feature_486 >  0.00\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |--- feature_372 >  0.00\n",
      "|   |   |   |--- class: 7\n",
      "|   |--- feature_155 >  0.00\n",
      "|   |   |--- feature_516 <= 0.19\n",
      "|   |   |   |--- class: 0\n",
      "|   |   |--- feature_516 >  0.19\n",
      "|   |   |   |--- class: 2\n",
      "|--- feature_405 >  0.00\n",
      "|   |--- feature_381 <= 0.22\n",
      "|   |   |--- feature_373 <= 0.00\n",
      "|   |   |   |--- feature_179 <= 0.01\n",
      "|   |   |   |   |--- feature_520 <= 0.25\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_520 >  0.25\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_179 >  0.01\n",
      "|   |   |   |   |--- class: 3\n",
      "|   |   |--- feature_373 >  0.00\n",
      "|   |   |   |--- class: 5\n",
      "|   |--- feature_381 >  0.22\n",
      "|   |   |--- feature_183 <= 0.05\n",
      "|   |   |   |--- feature_210 <= 0.07\n",
      "|   |   |   |   |--- class: 4\n",
      "|   |   |   |--- feature_210 >  0.07\n",
      "|   |   |   |   |--- class: 9\n",
      "|   |   |--- feature_183 >  0.05\n",
      "|   |   |   |--- feature_100 <= 0.00\n",
      "|   |   |   |   |--- feature_154 <= 0.00\n",
      "|   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_154 >  0.00\n",
      "|   |   |   |   |   |--- class: 3\n",
      "|   |   |   |--- feature_100 >  0.00\n",
      "|   |   |   |   |--- class: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree.export_text(dt.DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[516, 100, 486, 520, 210, 179, 372, 405, 373, 183, 154, 155, 381]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.find_features(dt.DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.DT.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e340a0a01ab186b377b016c01aa7d5d1230eddf285ffed81230a024c78a4da64"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
